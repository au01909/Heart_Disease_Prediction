{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from ucimlrepo import fetch_ucirepo\n",
        "# fetch dataset\n",
        "heart_disease = fetch_ucirepo(id=45)"
      ],
      "metadata": {
        "id": "_R0LMu2mbwVp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"heart.csv\")\n",
        "print(df.head())  # Print the first few rows\n",
        "print(df.info())  # Print data types and missing values\n",
        "print(df.describe()) # Print statistics\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AeyK5TZdWyc",
        "outputId": "b7406275-6026-4ea0-a9fb-1170811adf82"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
            "0   52    1   0       125   212    0        1      168      0      1.0      2   \n",
            "1   53    1   0       140   203    1        0      155      1      3.1      0   \n",
            "2   70    1   0       145   174    0        1      125      1      2.6      0   \n",
            "3   61    1   0       148   203    0        1      161      0      0.0      2   \n",
            "4   62    0   0       138   294    1        1      106      0      1.9      1   \n",
            "\n",
            "   ca  thal  target  \n",
            "0   2     3       0  \n",
            "1   0     3       0  \n",
            "2   0     3       0  \n",
            "3   1     3       0  \n",
            "4   3     2       0  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 14 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   age       1025 non-null   int64  \n",
            " 1   sex       1025 non-null   int64  \n",
            " 2   cp        1025 non-null   int64  \n",
            " 3   trestbps  1025 non-null   int64  \n",
            " 4   chol      1025 non-null   int64  \n",
            " 5   fbs       1025 non-null   int64  \n",
            " 6   restecg   1025 non-null   int64  \n",
            " 7   thalach   1025 non-null   int64  \n",
            " 8   exang     1025 non-null   int64  \n",
            " 9   oldpeak   1025 non-null   float64\n",
            " 10  slope     1025 non-null   int64  \n",
            " 11  ca        1025 non-null   int64  \n",
            " 12  thal      1025 non-null   int64  \n",
            " 13  target    1025 non-null   int64  \n",
            "dtypes: float64(1), int64(13)\n",
            "memory usage: 112.2 KB\n",
            "None\n",
            "               age          sex           cp     trestbps        chol  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.00000   \n",
            "mean     54.434146     0.695610     0.942439   131.611707   246.00000   \n",
            "std       9.072290     0.460373     1.029641    17.516718    51.59251   \n",
            "min      29.000000     0.000000     0.000000    94.000000   126.00000   \n",
            "25%      48.000000     0.000000     0.000000   120.000000   211.00000   \n",
            "50%      56.000000     1.000000     1.000000   130.000000   240.00000   \n",
            "75%      61.000000     1.000000     2.000000   140.000000   275.00000   \n",
            "max      77.000000     1.000000     3.000000   200.000000   564.00000   \n",
            "\n",
            "               fbs      restecg      thalach        exang      oldpeak  \\\n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  1025.000000   \n",
            "mean      0.149268     0.529756   149.114146     0.336585     1.071512   \n",
            "std       0.356527     0.527878    23.005724     0.472772     1.175053   \n",
            "min       0.000000     0.000000    71.000000     0.000000     0.000000   \n",
            "25%       0.000000     0.000000   132.000000     0.000000     0.000000   \n",
            "50%       0.000000     1.000000   152.000000     0.000000     0.800000   \n",
            "75%       0.000000     1.000000   166.000000     1.000000     1.800000   \n",
            "max       1.000000     2.000000   202.000000     1.000000     6.200000   \n",
            "\n",
            "             slope           ca         thal       target  \n",
            "count  1025.000000  1025.000000  1025.000000  1025.000000  \n",
            "mean      1.385366     0.754146     2.323902     0.513171  \n",
            "std       0.617755     1.030798     0.620660     0.500070  \n",
            "min       0.000000     0.000000     0.000000     0.000000  \n",
            "25%       1.000000     0.000000     2.000000     0.000000  \n",
            "50%       1.000000     0.000000     2.000000     1.000000  \n",
            "75%       2.000000     1.000000     3.000000     1.000000  \n",
            "max       2.000000     4.000000     3.000000     1.000000  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.metrics import (accuracy_score, precision_score, recall_score,\n",
        "                             f1_score, roc_auc_score, confusion_matrix,\n",
        "                             classification_report, roc_curve, ConfusionMatrixDisplay)\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "import joblib\n",
        "import warnings\n",
        "import mlflow\n",
        "import mlflow.xgboost\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up MLflow\n",
        "mlflow.set_experiment(\"Heart Disease Prediction - Simplified\")\n",
        "\n",
        "# 1. Data Loading and Preprocessing\n",
        "def load_and_preprocess_data(data_path=\"heart.csv\"):\n",
        "    \"\"\"Loads, preprocesses, and splits the heart disease dataset.  Simplified version.\n",
        "    Args:\n",
        "        data_path (str, optional): Path to the CSV file. Defaults to \"heart.csv\".\n",
        "\n",
        "    Returns:\n",
        "        tuple: X_train, X_test, y_train, y_test, feature_names\n",
        "    \"\"\"\n",
        "    print(\"Loading and preprocessing data...\")\n",
        "    df = pd.read_csv(data_path)\n",
        "\n",
        "    # Handle missing values using imputation\n",
        "    imputer = SimpleImputer(strategy='mean')  # Use 'mean', 'median', or 'most_frequent'\n",
        "    df.iloc[:, :] = imputer.fit_transform(df)\n",
        "\n",
        "    # Separate features and target variable\n",
        "    X = df[['age', 'sex', 'cp', 'trestbps', 'chol', 'thalach']]  # Key features only\n",
        "    y = df['target']\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # Feature scaling\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "    feature_names = list(X.columns)  # Store feature names\n",
        "    return X_train, X_test, y_train, y_test, feature_names\n",
        "\n",
        "# 2. Model Training (Simplified)\n",
        "def train_model(X_train, y_train, X_val, y_val, feature_names):\n",
        "    \"\"\"Trains an XGBoost model with MLflow logging. Simplified version.\n",
        "\n",
        "    Args:\n",
        "        X_train (array): Training features.\n",
        "        y_train (array): Training labels.\n",
        "\n",
        "    Returns:\n",
        "        XGBClassifier: Trained XGBoost model.\n",
        "    \"\"\"\n",
        "    with mlflow.start_run() as run:\n",
        "        # Define XGBoost model\n",
        "        model = XGBClassifier(objective='binary:logistic',\n",
        "                              eval_metric='auc',\n",
        "                              use_label_encoder=False,\n",
        "                              random_state=42)\n",
        "\n",
        "        # Train model\n",
        "        print(\"Training model...\")\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Log parameters and metrics to MLflow\n",
        "        mlflow.log_metric(\"train_roc_auc\", roc_auc_score(y_train, model.predict_proba(X_train)[:, 1])) # Add training ROC\n",
        "        mlflow.log_metric(\"val_roc_auc\", roc_auc_score(y_val, model.predict_proba(X_val)[:, 1])) # Log validation metric\n",
        "\n",
        "\n",
        "       # Log the model, including signature\n",
        "        input_example = X_train[:1]  # Use the first training sample as an example\n",
        "        mlflow.xgboost.log_model(\n",
        "            xgb_model=model,\n",
        "            artifact_path=\"xgboost-model\",\n",
        "            input_example=input_example\n",
        "            )\n",
        "        print(f\"MLflow Run ID: {run.info.run_id}\")\n",
        "    return model\n",
        "\n",
        "# 3. Model Evaluation and Validation\n",
        "def evaluate_model(model, X_test, y_test, feature_names):\n",
        "    \"\"\"Evaluates the trained model and logs metrics to MLflow.\n",
        "\n",
        "    Args:\n",
        "        model (XGBClassifier): Trained XGBoost model.\n",
        "        X_test (array): Testing features.\n",
        "        y_test (array): Testing labels.\n",
        "    \"\"\"\n",
        "    print(\"\\nEvaluating model...\")\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    auc = roc_auc_score(y_test, y_proba)\n",
        "\n",
        "    # Log metrics to MLflow\n",
        "    mlflow.log_metric(\"test_accuracy\", accuracy)\n",
        "    mlflow.log_metric(\"test_roc_auc\", auc)\n",
        "\n",
        "    # Confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(cm)\n",
        "    #Log confusion matrix as artifact\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    disp.plot()\n",
        "    plt.title('Confusion Matrix')\n",
        "    mlflow.log_figure(plt.gcf(), \"confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    # Classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # ROC Curve\n",
        "    fpr, tpr, thresholds = roc_curve(y_test, y_proba)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.plot(fpr, tpr, label=f\"AUC = {auc:.2f}\")\n",
        "    plt.plot([0, 1], [0, 1], linestyle='--')\n",
        "    plt.xlabel(\"False Positive Rate\")\n",
        "    plt.ylabel(\"True Positive Rate\")\n",
        "    plt.title(\"ROC Curve\")\n",
        "    plt.legend()\n",
        "    mlflow.log_figure(plt.gcf(), \"roc_curve.png\")\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"Accuracy: {accuracy:.4f}, AUC: {auc:.4f}\")\n",
        "\n",
        "# 4. Prediction Function (Simplified)\n",
        "def predict_heart_disease(model, new_data, imputer, scaler, feature_names):\n",
        "    \"\"\"Predicts heart disease probability for new data.\n",
        "\n",
        "    Args:\n",
        "        model (XGBClassifier): Trained XGBoost model.\n",
        "        new_data (dict): New patient data (dictionary format).\n",
        "        feature_names (list): list of feature names\n",
        "\n",
        "    Returns:\n",
        "        tuple: Probability of heart disease, Predicted class (0 or 1).\n",
        "    \"\"\"\n",
        "    print(\"\\nPredicting for new data...\")\n",
        "\n",
        "    # 1. Ensure correct feature order is passed.\n",
        "    new_data_df = pd.DataFrame([new_data], columns=feature_names)\n",
        "\n",
        "    # 2. Transform new data using the fitted imputer and scaler\n",
        "    new_data_imputed = imputer.transform(new_data_df)\n",
        "    new_data_scaled = scaler.transform(new_data_imputed)\n",
        "\n",
        "\n",
        "    pred_proba = model.predict_proba(new_data_scaled)[:, 1]\n",
        "    pred_class = 1 if pred_proba >= 0.5 else 0  # Threshold of 0.5\n",
        "\n",
        "    return pred_proba[0], pred_class\n",
        "\n",
        "# 5. Main Execution Block\n",
        "if __name__ == \"__main__\":\n",
        "    # Enable autologging\n",
        "    mlflow.xgboost.autolog()\n",
        "\n",
        "    #Data loading and preprocessing\n",
        "    X_train, X_test, y_train, y_test, feature_names = load_and_preprocess_data(\"heart.csv\")\n",
        "\n",
        "    # Create validation set\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)\n",
        "\n",
        "   # Train the imputer and scaler on the training data\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    imputer.fit(X_train)\n",
        "    X_train = imputer.transform(X_train)\n",
        "    X_test = imputer.transform(X_test)  # Apply to test data\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(X_train)\n",
        "    X_train = scaler.transform(X_train)\n",
        "    X_test = scaler.transform(X_test)  # Apply to test data\n",
        "\n",
        "    # Train model\n",
        "    model = train_model(X_train, y_train, X_val, y_val, feature_names)\n",
        "\n",
        "    # Evaluate model\n",
        "    evaluate_model(model, X_test, y_test, feature_names)\n",
        "\n",
        "    # Example Prediction - data needs to be a dictionary\n",
        "    new_patient_data = {\n",
        "        'age': 52,\n",
        "        'sex': 1,\n",
        "        'cp': 0,\n",
        "        'trestbps': 125,\n",
        "        'chol': 212,\n",
        "        'thalach': 168 #Removed some columns as they were useless\n",
        "    }\n",
        "\n",
        "    #Need to specify feature_names for the sample data.\n",
        "    probability, prediction = predict_heart_disease(model, new_patient_data, imputer, scaler, feature_names) # Pass imputer and scaler\n",
        "    print(f\"\\nPrediction Results:\")\n",
        "    print(f\"  Probability of Heart Disease: {probability:.4f}\")\n",
        "    print(f\"  Prediction: {'Heart Disease Present' if prediction == 1 else 'No Heart Disease'}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "eLQe6w9GfD19",
        "outputId": "fb19bc07-3572-4469-c1da-4752841ae5e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/03/19 08:31:35 INFO mlflow.tracking.fluent: Experiment with name 'Heart Disease Prediction - Simplified' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preprocessing data...\n",
            "Training model...\n",
            "MLflow Run ID: 2e42cbb1357d4ede8138d1671dd7afaa\n",
            "\n",
            "Evaluating model...\n",
            "Confusion Matrix:\n",
            "[[ 96   4]\n",
            " [  0 105]]\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98       100\n",
            "           1       0.96      1.00      0.98       105\n",
            "\n",
            "    accuracy                           0.98       205\n",
            "   macro avg       0.98      0.98      0.98       205\n",
            "weighted avg       0.98      0.98      0.98       205\n",
            "\n",
            "Accuracy: 0.9805, AUC: 1.0000\n",
            "\n",
            "Predicting for new data...\n",
            "\n",
            "Prediction Results:\n",
            "  Probability of Heart Disease: 0.1401\n",
            "  Prediction: No Heart Disease\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "602YfvYifPPj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}